<div class="rpg-chatbot-settings">
    <div class="inline-drawer">
        <div class="inline-drawer-toggle inline-drawer-header">
            <b>RPG Character Chatbot - State Tracking</b>
            <div class="inline-drawer-icon fa-solid fa-circle-chevron-down down"></div>
        </div>
        <div class="inline-drawer-content">
            <!-- Enable/Disable -->
            <div class="rpg_block flex-container">
                <input id="rpg_enabled" type="checkbox" />
                <label for="rpg_enabled"><b>Enable RPG Character Chatbot</b></label>
            </div>
            <small>Activates LLM-A for state tracking. Your SillyTavern connection profile will act as LLM-B.</small>

            <hr class="sysHR" />

            <!-- LLM-A Configuration -->
            <h4>LLM-A (State Tracking & Context Analysis)</h4>
            <small>Recommended: Fast, cheap model like GPT-3.5, Claude Haiku, or free Llama 3.2 3B via OpenRouter</small>

            <div class="rpg_block">
                <label for="rpg_llm_a_provider">Provider</label>
                <select id="rpg_llm_a_provider" class="text_pole">
                    <option value="openai">OpenAI</option>
                    <option value="anthropic">Anthropic</option>
                    <option value="openrouter">OpenRouter</option>
                </select>
            </div>

            <div class="rpg_block">
                <label for="rpg_llm_a_api_key">API Key</label>
                <input id="rpg_llm_a_api_key" type="password" class="text_pole" placeholder="Enter API key" />
            </div>

            <div class="rpg_block">
                <label for="rpg_llm_a_model">Model</label>
                <input id="rpg_llm_a_model" type="text" class="text_pole" placeholder="gpt-3.5-turbo" />
                <small>Examples: gpt-3.5-turbo, claude-3-haiku-20240307, meta-llama/llama-3.2-3b-instruct:free</small>
            </div>

            <div class="rpg_block">
                <label for="rpg_llm_a_temperature">Temperature</label>
                <input id="rpg_llm_a_temperature" class="text_pole" type="number" min="0" max="2" step="0.1" value="0.3" />
                <small>Lower is better for structured output</small>
            </div>

            <div class="rpg_block">
                <label for="rpg_llm_a_max_tokens">Max Tokens</label>
                <input id="rpg_llm_a_max_tokens" class="text_pole" type="number" min="100" max="4000" step="100" value="1000" />
            </div>

            <hr class="sysHR" />

            <!-- LLM-B Info -->
            <h4>LLM-B (Main Roleplay Model)</h4>
            <div class="rpg_block">
                <p><b>âœ“ Using SillyTavern's Default Connection Profile</b></p>
                <small>Configure your main roleplay model in SillyTavern's API Connections. The extension will inject context from LLM-A into your configured model's prompt.</small>
            </div>

            <hr class="sysHR" />

            <!-- Advanced Options -->
            <h4>Advanced Options</h4>

            <div class="rpg_block flex-container">
                <input id="rpg_debug_mode" type="checkbox" />
                <label for="rpg_debug_mode">Debug Mode</label>
                <small>Show LLM-A analysis in console and on-screen</small>
            </div>

            <div class="rpg_block flex-container">
                <input id="rpg_memory_compression" type="checkbox" checked />
                <label for="rpg_memory_compression">Enable Memory Compression</label>
                <small>Compress old messages to maintain long-term context</small>
            </div>

            <div class="rpg_block flex-container">
                <input id="rpg_show_state_panel" type="checkbox" checked />
                <label for="rpg_show_state_panel">Show State Panel</label>
                <small>Display current character state above chat</small>
            </div>

            <hr class="sysHR" />

            <!-- Smart Context Management (THE KEY FEATURE FOR BUDGET ROLEPLAYERS!) -->
            <h4>ðŸ’° Smart Context Management (Token Savings)</h4>
            <small><b>This is what ACTUALLY saves money on premium models!</b> Replaces full chat history with compressed context.</small>

            <div class="rpg_block">
                <label for="rpg_smart_context_mode">Context Compression Mode</label>
                <select id="rpg_smart_context_mode" class="text_pole">
                    <option value="off">Off - Use full history (no savings)</option>
                    <option value="minimal">Minimal - Keep 3 messages (~70% token savings)</option>
                    <option value="balanced" selected>Balanced - Keep 6 messages (~50% token savings)</option>
                    <option value="aggressive">Aggressive - Keep 10 messages (~30% token savings)</option>
                </select>
                <small><b>Recommended: Balanced</b> - Perfect for long chats with premium models</small>
            </div>

            <div class="rpg_block flex-container">
                <input id="rpg_compress_character_card" type="checkbox" checked />
                <label for="rpg_compress_character_card">Compress Character Card</label>
                <small>Reduces char card from 1000-2000 tokens â†’ 300 tokens (keeps key traits)</small>
            </div>

            <div class="rpg_block">
                <label for="rpg_max_char_card_tokens">Max Character Card Tokens</label>
                <input id="rpg_max_char_card_tokens" class="text_pole" type="number" min="100" max="1000" step="50" value="300" />
                <small>Target size for compressed character description</small>
            </div>

            <div class="rpg_block flex-container">
                <input id="rpg_inject_state_as_context" type="checkbox" checked />
                <label for="rpg_inject_state_as_context">Use State Tracking as Context</label>
                <small>Replaces old messages with compressed state (affection, mood, recent events)</small>
            </div>

            <div class="rpg_block">
                <h5>ðŸ’¡ How This Saves Money:</h5>
                <div style="background: #1a1a1a; padding: 10px; border-radius: 5px; margin-top: 5px;">
                    <p style="margin: 5px 0;"><b>Without compression:</b></p>
                    <ul style="margin: 5px 0; padding-left: 20px;">
                        <li>Full char card: ~1500 tokens</li>
                        <li>100 message chat: ~10,000 tokens</li>
                        <li><b>Total: ~11,500 tokens per message</b></li>
                        <li>GPT-4: $0.115 per message</li>
                        <li>100 messages = <b>$11.50</b></li>
                    </ul>
                    <p style="margin: 5px 0;"><b>With "Balanced" compression:</b></p>
                    <ul style="margin: 5px 0; padding-left: 20px;">
                        <li>Compressed char card: ~300 tokens</li>
                        <li>Compressed history: ~500 tokens</li>
                        <li>Recent 6 messages: ~600 tokens</li>
                        <li>State context: ~200 tokens</li>
                        <li><b>Total: ~1,600 tokens per message</b></li>
                        <li>GPT-4: $0.016 per message</li>
                        <li>100 messages = <b>$1.60</b></li>
                    </ul>
                    <p style="margin: 5px 0; color: #4CAF50;"><b>ðŸ’° Savings: $9.90 per 100 messages (86% reduction!)</b></p>
                </div>
            </div>

            <hr class="sysHR" />

            <!-- Actions -->
            <div class="rpg_block flex-container">
                <input id="rpg_reset_state" class="menu_button" type="submit" value="Reset State" />
            </div>

            <hr class="sysHR" />

            <!-- Information -->
            <div class="rpg_block">
                <h4>How It Works</h4>
                <p>Two-LLM architecture for immersive roleplay:</p>
                <ul>
                    <li><b>LLM-A</b>: Tracks state (mood, clothes, environment) and analyzes context</li>
                    <li><b>LLM-B</b>: Your SillyTavern model receives filtered context and generates responses</li>
                    <li><b>Detailed Tracking</b>: Mood, location, clothing state, scene intensity, POV shifts</li>
                    <li><b>Smart Adaptation</b>: Detects conversation mode (short/balanced/detailed)</li>
                    <li><b>Memory Compression</b>: Maintains context in long conversations</li>
                </ul>
                <p><a href="https://github.com/Aryangpt007/Project_Smartex" target="_blank">Documentation & GitHub</a></p>
            </div>
        </div>
    </div>
</div>
